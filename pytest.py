# PYTHONPATH=../datacubes-lib/ pytest -vv tests_scripts/tests_lr_module/

import pandas as pd
import json
from scripts.lossrun import JugadParserZ
from deepdiff import DeepDiff
import os
from os import listdir
from pprint import pprint
from statistics import mode
import pprint
import time
import datetime
import xml.etree.ElementTree as ET

HERE = os.path.dirname(os.path.abspath(__file__))
model_outputs_dir = HERE + "/model_files"
json_output_dir = HERE + "/output_json_files"
model_output_files = listdir(model_outputs_dir)
json_output_files = listdir(json_output_dir)
xml_file = HERE + "/client_fields.xml"
tree = ET.parse(xml_file)

def testing_couple_files(model_output_files, json_output_files):
    if '.DS_Store' in model_output_files:
        model_output_files.remove('.DS_Store')
    if '.DS_Store' in json_output_files:
        json_output_files.remove('.DS_Store')

    matched_entries = []
    for json_files in json_output_files:
        for model_files in model_output_files:
            if json_files[:-5] in model_files:
                matched_entries.append([json_files, model_files])

    return matched_entries


carriers = ["Liberty Multual", "AIG", "Amerisure", "CNA", "Cincinnati", "ProSight"]

s_carrier = []


def carrier_selection(list_sentences, file_name):
    search = []
    for items in carriers:
        for i in range(0, len(list_sentences)):
            if items.lower() in list_sentences[i].lower():
                search.append(items)
    if len(search) > 0:
        s_carrier.append([mode(search), file_name])
        return mode(search)
    else:
        s_carrier.append(["UNKNOWN", file_name])
        return "UNKNOWN"


def claims_per_page_num(grouped, page_num):
    if page_num in grouped["page_num"].tolist():
        return int(grouped[grouped["page_num"] == page_num]['counts'])
    else:
        return "N/A"


def comparison_data(file_name, tester):
    df_main = pd.read_csv(file_name)
    val = df_main.to_json(orient="records")
    model_json = json.loads(val)
    config_json = {'skip_JugadCleaner': False}
    resp_val = {'model': model_json, 'config': config_json}
    print(file_name)
    carr = carrier_selection(df_main["sentence"].tolist(), file_name)
    updated_parse = JugadParserZ.process_prediction_file(resp_val, load_from_json=True, client_name='test',
                                                         carrier={"1": [carr]})
    result_df = pd.DataFrame(updated_parse[0]['data'])
    result_df = result_df[JugadParserZ.features()]
    result_df = result_df.reindex_axis(sorted(result_df.columns), axis=1)
    result_df = result_df.drop(["Claim_Type", "Coverage", "Carrier"], axis=1)

    with open(tester) as data_file:
        expected_json = json.load(data_file)
    print (expected_json)

    frame = []
    for i in range(0, len(expected_json["result"])):
        df = pd.Series(expected_json["result"][i])
        # df=df.to_frame().reset_index().T
        frame.append(df)

    expected_df = pd.concat(frame, axis=1).T
    expected_df = expected_df.drop(["Carrier"], axis=1)

    # searching for the date columns
    date_columns = []
    for c in list(result_df.columns):
        if "date" in c.lower():
            date_columns.append(c)
    date_columns.append("Policy_Period_End")
    date_columns.append("Policy_Period_Start")

    # modifying the date columns to datetime
    for items in date_columns:
        result_df[items] = pd.to_datetime(result_df[items])
        # considering that the master json has less columns than the one generated by JugadParserZ
        if items in list(expected_df.columns):
            try:
                expected_df[items] = pd.to_datetime(expected_df[items])
            except:
                expected_df[items] = expected_df[items]

    non_list = ["Claim_Number", "Claim_Status", "Line_of_Business", "Policy_Number", "accident_description", ]

    # other_columns=[]
    # for m in list(result_df.columns):
    #     if m not in date_columns:
    #         if m not in non_list:
    #             other_columns.append(m)

    result_dict = result_df.to_dict()
    expected_dict = expected_df.to_dict()

    return result_dict, expected_dict

def carrier(file_name):
    for listed in s_carrier:
        if file_name in listed[1]:
            return listed[0]

def report_generation(ddiff_result_df, t1, t2):
    report_dict = {"error_info": [], "correct_value": [], "incorrect_value": [], "file_name": [], "carrier": [],
                   "page": [], "claim_count_model": [], "claim_count_json": [], "claim_identifier": []}
    t1_page_group = t1.groupby(["page_num"]).size().reset_index(name="counts")
    t2_page_group = t2.groupby(["page_num"]).size().reset_index(name="counts")
    for m in range(0, len(ddiff_result_df["file_name"])):
        if ddiff_result_df["result"][m] == "Error Found":
            error_text = ddiff_result_df["report"][m]
            error_columns = []
            for cols in JugadParserZ.features():
                if cols not in error_columns:
                    if cols in str(error_text):
                        error_columns.append(cols)
            reps = min(len(t1), len(t2))
            for items in error_columns:
                for i in range(0, reps):
                    if t1[items][i] != t2[items][i]:
                        report_dict["correct_value"].append(t2[items][i])
                        report_dict["incorrect_value"].append(t1[items][i])
                        report_dict["error_info"].append(items)
                        report_dict["file_name"].append(ddiff_result_df["file_name"][m])
                        report_dict["carrier"].append(carrier(ddiff_result_df["file_name"][m]))
                        report_dict["page"].append(t1["page_num"][i])
                        report_dict["claim_count_model"].append(claims_per_page_num(t1_page_group, t1["page_num"][i]))
                        report_dict["claim_count_json"].append((claims_per_page_num(t2_page_group, t1["page_num"][i])))
                        report_dict["claim_identifier"].append(i)

    return pd.DataFrame(report_dict)



def test_compare_jsons():
    matched_entries = testing_couple_files(model_output_files, json_output_files)
    frames = []
    for entries in matched_entries:
        ddiff_result = {"file_name": [], "result": [], "report": []}  # , "carrier": []}

        file_name = HERE + "/model_files/" + entries[1]
        tester = HERE + "/output_json_files/" + entries[0]

        t1, t2 = comparison_data(file_name, tester)
        ddiff = (DeepDiff(t1, t2, significant_digits=0))
        dict = ddiff.__dict__
        ddiff_result["file_name"].append(entries[0][:-5])

        # print("\n\n\n\n Compared these files:\n\n\n\n{}\n{}\n\n\n\n".format(file_name,tester))

        if "values_changed" in dict["tree"]:
            ddiff_result["result"].append("Error Found")
            final_report = str(dict["tree"]["values_changed"])
            ddiff_result["report"].append(final_report)
            print(final_report)
        else:
            ddiff_result["result"].append("Pass")
            ddiff_result["report"].append("Pass")
        df = report_generation(pd.DataFrame(ddiff_result), pd.DataFrame(t1), pd.DataFrame(t2))
        frames.append(df)

    #ddiff_result_df["carrier"] = s_carrier
    # ddiff_result_df=report_generation(pd.DataFrame(ddiff_result), pd.DataFrame(t1), pd.DataFrame(t2))
    ddiff_result_df = pd.concat(frames)
    ddiff_result_df = ddiff_result_df.reset_index()
    ts = time.time()
    st = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d_%H_%M_%S')
    header= ["carrier", "file_name", "page", "error_info", "claim_identifier", "correct_value", "incorrect_value", "claim_count_model", "claim_count_json" ]
    root=tree.getroot()
    cleaner=[]
    for i in range(len(ddiff_result_df)):
        for j in range(len(root)):
            if str(ddiff_result_df["carrier"][i]) in str(root[j]):
                for k in range(0,len(root[j])):
                    appender= [str(ddiff_result_df["carrier"][i]), root[j][k].text]
                    if appender not in cleaner:
                        cleaner.append(appender)
    if len(cleaner)>0:
        for data in cleaner:
            ddiff_result_df=ddiff_result_df[(ddiff_result_df["carrier"]!=data[0]) | (ddiff_result_df["error_info"]!=data[1])]

    ddiff_result_df=ddiff_result_df.sort_values(by= ["carrier" , "file_name"])
    ddiff_result_df.to_csv(HERE + "/test_report_{}.csv".format(st), index= None, columns= header)
    # assert "Error Found" not in ddiff_result["result"]


if __name__ == "__main__":
    test_compare_jsons()
